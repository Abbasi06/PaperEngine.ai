# PaperEngine.ai
### The Intelligent Multi-Modal Research & Learning Assistant

**PaperEngine.ai** is a comprehensive AI platform designed to transform complex research papers and academic documents into structured, multi-modal learning assets. By leveraging a sophisticated multi-agent orchestration layer, it automates document ingestion, visual analysis of scientific figures, real-time research, and the generation of interactive study tools like quizzes, presentations, and mind maps.

---

## ðŸ—ï¸ System Architecture
The system is built on a modular, containerized microservices architecture to ensure high-fidelity outputs and scalability.

![System Design Diagram](Research_and_design.jpeg)

* **Frontend:** A modern Vite + React interface featuring a conversational research environment, floating academic-themed backgrounds, and specialized artifact viewers.
* **Orchestration (LangGraph Agent):** A state-machine-driven agent that manages user intent routing, maintains session state, and executes multi-step research plans.
* **API Gateway:** The central entry point managing sessions and streaming real-time progress updates from the agent to the frontend.
* **Specialized Microservices:**
    * **Brain Service:** Powers high-level reasoning and RAG-based answering using **Llama-3.2-3B**.
    * **Vision Service:** Analyzes complex scientific figures and data trends using **Qwen2.5-VL**.
    * **Embedding Service:** Vectorizes content for semantic search via **Qwen3-Embedding**.
    * **Atomic Services:** Core tools for PDF conversion (Marker), academic scraping (Arxiv, Wikipedia), and asset generation.

---

## ðŸš€ Key Features

### ðŸ“„ Intelligent Multi-Modal Ingestion
* **High-Fidelity PDF Parsing:** Converts scientific PDFs into clean Markdown using the Marker library.
* **Visual Figure Enrichment:** Automatically extracts and captions images, charts, and diagrams within papers to maintain context through Vision LLMs.

### ðŸ” Automated Research & RAG
* **Hybrid Search:** Synthesizes data from Arxiv, Wikipedia, and DuckDuckGo to ground agent responses in factual evidence.
* **Semantic Memory:** Stores document insights in a ChromaDB vector store for context-aware retrieval and long-term research continuity.

### ðŸŽ¨ Advanced Asset Generation
* **Fine-Tuned Presentation Architect:** Utilizes a Phi-2 model fine-tuned via QLoRA to architect professional presentation blueprints from raw document context.
* **Comprehensive Study Suite:** Generates dynamic Quizzes, Flashcards, Mermaid.js Mind Maps, and YouTube/Podcast scripts tailored to user learning styles.

---

## ðŸ› ï¸ Model Inventory
The system utilizes specialized **GGUF** models for efficient local inference:

| Component | Model | File | Size |
| :--- | :--- | :--- | :--- |
| **Brain** (Text Agent) | Llama-3.2-3B-Instruct | `Llama-3.2-3B-Instruct-Q4_K_M.gguf` | ~1.97GB |
| **Vision** (The Eyes) | Qwen2.5-VL-3B-Instruct | `Qwen2.5-VL-3B-Instruct-q4_k_m.gguf` | ~1.88GB |
| **Vision Adapter** | Qwen2.5-VL-3B-Instruct | `mmproj-f16.gguf` | ~1.3GB |
| **Embedding** | Qwen3-Embedding-0.6B | `Qwen3-Embedding-0.6B-f16.gguf` | ~1.17GB |

---

## ðŸ§  Agentic Workflow
The PaperEngine Agent follows a strict logical sequence to ensure high-fidelity outputs:

1. **Intent Router:** Determines if the user intent is casual chat, a research question, or a document-based study task.
2. **Interviewer:** Probes for specific user preferences (Learning Style/Depth) if they have not been established.
3. **Planner:** Constructs a dynamic execution plan (e.g., Ingest PDF -> Research Gaps -> Store Memory -> Generate Assets).
4. **Executor:** Iteratively calls specialized microservice tools until the plan is fulfilled and the artifacts are ready for review.

---

## ðŸš¦ Getting Started

### 1. Model Synchronization
Download the necessary GGUF model weights and adapters to the `models/` directory:
```bash
python download_models.py
```
### 2. Deployment with Docker
Launch the entire ecosystemâ€”including the brain, vision, embedding, and atomic servicesâ€”using Docker Compose:
```bash
docker-compose up --build
```
### 3. Usage
Upon startup, the agent will prompt for your Learning Style (Reading, Watching, Listening) and Depth Level (Layman, Researcher) to customize all generated artifacts.

---
## ðŸ“‚ Project Structure: PaperEngine.ai

```text
PaperEngine.ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ agent_graph.py           # LangGraph orchestration and state management
â”‚   â”‚   â”œâ”€â”€ atomic_services.py       # Core tools (Search, PDF Ingestion, Memory)
â”‚   â”‚   â”œâ”€â”€ brain_service.py         # Llama-3.2-3B engine manager
â”‚   â”‚   â”œâ”€â”€ embedding_service.py     # Qwen3-Embedding engine manager
â”‚   â”‚   â”œâ”€â”€ image_caption_service.py # Qwen2.5-VL vision engine manager
â”‚   â”‚   â””â”€â”€ prompts.py               # Prompt templates for study assets
        â””â”€â”€ prompts.py
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ api_gateway.py           # Central FastAPI gateway & streaming
â”‚   â”‚   â”œâ”€â”€ inference_generator.py   # Fine-tuned Phi-2 inference logic
â”‚   â”‚   â””â”€â”€ pptx_service.py          # PPTX assembly & Phi-2 blueprinting
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ Qlora_Finetuning_Phi3.py # Phi-2 QLoRA training script
â”œâ”€â”€ frontend/                        # Vite + React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                  # Main UI & Agent interaction logic
â”‚   â”‚   â”œâ”€â”€ main.jsx                 # React entry point
â”‚   â”‚   â””â”€â”€ index.css                # Global styles and hero animations
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ models/                          # GGUF Model weights and adapters
â”‚   â”œâ”€â”€ Llama-3.2-3B-Instruct-Q4_K_M.gguf
â”‚   â”œâ”€â”€ Qwen2.5-VL-3B-Instruct-q4_k_m.gguf
â”‚   â””â”€â”€ final_phi_json_adapter/      # Trained LoRA weights
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/                   # Persistent vector storage
â”‚   â””â”€â”€ images/                      # Extracted document images
â”œâ”€â”€ uploads/                         # Temporary user-uploaded PDFs
â”œâ”€â”€ docker-compose.yml               # Multi-container orchestration
â”œâ”€â”€ dockerfile                       # Backend container definition
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ download_models.py               # Model synchronization utility



